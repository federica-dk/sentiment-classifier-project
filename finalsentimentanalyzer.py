# -*- coding: utf-8 -*-
"""FinalSentimentAnalyzer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13CYXbcvYQRyLYmkWDx1bcV5tFLbEpd0l
"""

#Imports
import pandas as pd
import numpy as np
import nltk
import re
import seaborn as sns
import matplotlib.pyplot as plt
import os
import tempfile
import matplotlib as mpl

from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score, mean_absolute_error, confusion_matrix, roc_curve, auc
from sklearn.naive_bayes import MultinomialNB
from wordcloud import WordCloud

#Downloading th necessary data from NLTK
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt_tab')

#Opening the file
df = pd.read_csv('/content/Tweets.csv')

#data exploration
print('Sentiment Column Description:')
print(df['sentiment'].describe())

print('Twitter Data Head')
df.head()

#Cleaning the data
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

#Cleaning text function to remove any unecessary data that may cloud results
def clean_text(text):
  text = str(text).lower()
  text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
  text = re.sub(r'@\w+', '', text)
  text = re.sub(r'#', '', text)
  text = re.sub(r'[^a-z\s]', '', text)
  #Creating the tokens of the text
  tokens = nltk.word_tokenize(text)
  #Lemmatizing the data
  tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and len(word) > 1]
  return " ".join(tokens)

 #Calling function
df['clean_text'] = df['text'].apply(clean_text)

#Checking the function is working correctly
df['clean_text'].head()

#Creating the Class Balance visual
sentiment_counts = df['sentiment'].value_counts()
sns.countplot(x='sentiment', data=df, order=['positive','neutral','negative'])
plt.title('Sentiment Class Balance')
plt.show()

#Spliting data
df['clean_text'] = df['text'].apply(clean_text)
X = df['clean_text']
y = df['sentiment']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

vectorizer = TfidfVectorizer()
X_train_vectors = vectorizer.fit_transform(X_train)
X_test_vectors = vectorizer.transform(X_test)

#Naive Bayes baseline
nb_model = MultinomialNB()
nb_model.fit(X_train_vectors, y_train)

y_pred_nb = nb_model.predict(X_test_vectors)
print("Naive Bayes Accuracy:", accuracy_score(y_test, y_pred_nb))
print("Naive Bayes Classification Report:\n", classification_report(y_test, y_pred_nb))

nb_cm = confusion_matrix(y_test, y_pred_nb)
sns.heatmap(nb_cm, annot=True, fmt='d', cmap='Blues')
plt.title('Naive Bayes Confusion Matrix')
plt.show()

svm_model = SVC()
svm_model.fit(X_train_vectors, y_train)

y_pred_svm = svm_model.predict(X_test_vectors)

#Accuracy Score + Classification report
print(f'SVM Accuracy: { accuracy_score(y_test, y_pred_svm)}')
print(f'Classification Report: {classification_report(y_test, y_pred_svm)}')

#Confusion Matrix
svm_cm = confusion_matrix(y_test, y_pred_svm)
sns.heatmap(svm_cm, annot=True, fmt='d', cmap='Pinks')
plt.title('SVM Confusion Matrix')
plt.show()

#ROC Curve (ROC = a visual representation of model performance across all thresholds)

#filter positive and negative for ROC
df_binary = df[df['sentiment'].isin(['positive', 'negative'])]
X_bin = df_binary['clean_text']
y_bin = df_binary['sentiment'].map({'negative':0, 'positive':1})
X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(
    X_bin, y_bin, test_size=0.2, random_state=42
)

X_train_vec_b = vectorizer.fit_transform(X_train_b)
X_test_vec_b = vectorizer.transform(X_test_b)

svm_bin = SVC(probability=True)
svm_bin.fit(X_train_vec_b, y_train_b)

y_scores = svm_bin.predict_proba(X_test_vec_b)[:,1]

fpr, tpr, thresholds = roc_curve(y_test_b, y_scores)
roc_auc = auc(fpr, tpr)

#Output
plt.figure(figsize=(8,6))
plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')
plt.plot([0,1],[0,1],'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('SVM ROC Curve (Pos vs. Neg)')
plt.legend()
plt.show()

#Grid Search for SVM
param_grid = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf']
}

grid = GridSearchCV(SVC(), param_grid, cv=3)
grid.fit(X_train_vectors, y_train)

print("Best Params:", grid.best_params_)
print("Best Score:", grid.best_score_)

#Generating Word Clouds

# Word Cloud for Top Positive Words
if positive_text: # Only generate if there's text
    plt.figure(figsize=(12, 8))
    wordcloud_positive = WordCloud(
        width=1000,
        height=500,
        background_color='white',
        colormap='viridis', # A nice colormap for positive words
        min_font_size=10,
        max_words=100 # Limit to top 100 words
    ).generate(positive_text)

    plt.imshow(wordcloud_positive, interpolation='bilinear')
    plt.axis('off') # Hide axes
    plt.title('Top Positive Words', fontsize=16)
    plt.show() # Display the plot
else:
    print("No positive text found for word cloud generation.")

# Word Cloud for Top Negative Words
if negative_text: # Only generate if there's text
    plt.figure(figsize=(12, 8))
    wordcloud_negative = WordCloud(
        width=1000,
        height=500,
        background_color='black', # Dark background for negative words
        colormap='inferno', # A colormap that might convey intensity
        min_font_size=10,
        max_words=100 # Limit to top 100 words
    ).generate(negative_text)

    plt.imshow(wordcloud_negative, interpolation='bilinear')
    plt.axis('off') # Hide axes
    plt.title('Top Negative Words', fontsize=16, color='white') # Title color for visibility on black background
    plt.show() # Display the plot
else:
    print("No negative text found for word cloud generation.")

# Optional: Word Cloud for Top Neutral Words
if neutral_text:
    plt.figure(figsize=(12, 8))
    wordcloud_neutral = WordCloud(
        width=1000,
        height=500,
        background_color='grey', # A neutral background
        colormap='magma', # A different colormap
        min_font_size=10,
        max_words=100
    ).generate(neutral_text)

    plt.imshow(wordcloud_neutral, interpolation='bilinear')
    plt.axis('off')
    plt.title('Top Neutral Words', fontsize=16)
    plt.show() # Display the plot
else:
    print("No neutral text found for word cloud generation.")
#Create Count Plot for Sentiment Class Balance

plt.figure(figsize=(8, 6))
# Ensure 'sentiment' column exists in df
sns.countplot(x='sentiment', data=df, palette='coolwarm', order=['positive', 'neutral', 'negative'])
plt.title('Sentiment Class Balance', fontsize=16)
plt.xlabel('Sentiment Class', fontsize=12)
plt.ylabel('Number of Entries', fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.7) # Add a grid for better readability
plt.show() # Display the plot